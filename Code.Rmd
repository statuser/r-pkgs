# (PART) Package components {-}

```{r, include = FALSE}
source("common.R")
```

# R code {#r}

The first principle of making a package is that all R code goes in the `R/` directory.
In this chapter, you'll learn about organising your functions into files, maintaining a consistent style, and recognizing the stricter requirements for functions in a package (versus in a script).
We'll also remind you of the fundamental workflows for test-driving and formally checking an in-development package: `load_all()`, `test()`, and `check()`.

## Organise functions into files {#code-organising}

The only hard rule is that your package should store its function definitions in R scripts, i.e. files with extension `.R`, that live in the `R/` directory[^no-subdirs].
However, a few more conventions can make the source code of your package easier to navigate and relieve you of re-answering "How should I name this?" each time you create a new file.
The Tidyverse Style Guide offers some [general advice about file names](https://style.tidyverse.org/files.html) and also [advice that specifically applies to files in a package](https://style.tidyverse.org/package-files.html).
We expand on this here.

[^no-subdirs]: Unfortunately you can't use subdirectories inside `R/`.
The next best thing is to use a common prefix, e.g., `abc-*.R`, to signal that a group of files are related.

The file name should be meaningful and convey which functions are defined within.
While you're free to arrange functions into files as you wish, the two extremes are bad: don't put all functions into one file and don't put each function into its own separate file.
This advice should inform your general policy, but there are exceptions to every rule.
If a specific function is very large or has lots of documentation, it can make sense to give it its own file, named after the function.
More often, a single `.R` file will contain multiple function definitions: such as a main function and its supporting helpers, a family of related functions, or some combination of the two.

Here are some examples from the actual source of the [tidyr package](http://tidyr.tidyverse.org/) at version 1.1.2.
There are some departures from the hard-and-fast rules given above, which illustrates that there's a lot of room for judgment here.

```{r include = FALSE}
library(tidyverse)

tidyr_separate <- tibble(
  `Organising principle` = "Main function plus helpers",
  `Source file` = "[tidyr/R/separate.R](https://github.com/tidyverse/tidyr/blob/v1.1.2/R/separate.R)",
  Comments = "Defines the user-facing `separate()` (an S3 generic), a `data.frame` method, and private helpers"
)

tidyr_rectangle <- tibble(
  `Organising principle` = "Family of functions",
  `Source file` = "[tidyr/R/rectangle.R](https://github.com/tidyverse/tidyr/blob/v1.1.2/R/rectangle.R)",
  Comments = "Defines a family of functions for \"rectangling\" nested lists (`hoist()` and the `unnest()` functions), all documented together in a big help topic, plus private helpers"
)

tidyr_uncount <- tibble(
  `Organising principle` = "One function",
  `Source file` = "[tidyr/R/uncount.R](https://github.com/tidyverse/tidyr/blob/v1.1.2/R/uncount.R)",
  Comments = "Defines exactly one function, `uncount()`, that's not particulary large, but doesn't fit naturally into any other `.R` file"
)
 
dat <- bind_rows(tidyr_uncount, tidyr_separate, tidyr_rectangle)
```

```{r echo = FALSE}
knitr::kable(dat)
```

:::tip
Another file you often see in the wild is `R/utils.R`.
This is a common place to define small utilities that are used inside multiple package functions.
Since they serve as helpers to multiple functions, placing them in `R/utils.R` makes them easier to re-discover when you return to your package after a long break.

Bob Rudis assembled a collection of such files and did some analysis in the post [Dissecting R Package “Utility Belts”](https://rud.is/b/2018/04/08/dissecting-r-package-utility-belts/).
:::
  
If it's very hard to predict which file a function lives in, that suggests it's time to separate your functions into more files or reconsider how you are naming your functions and/or files.

:::rstudio-tip
The organisation of functions within files is less important in RStudio, which offers two ways to jump to the definition of a function:

* Press Ctrl + . (the period) then start typing the name. Keep typing to narrow
  the list and eventually pick a function (or file) to visit. This works for both
  functions and files in your project.
      
    ```{r, echo = FALSE}
    knitr::include_graphics("images/file-finder.png", dpi = 220)
    ```
  
* With your cursor in a function name or with a function name selected, press
  F2. This works for functions defined in your package or in another package.

After navigating to a function with one of these methods, return to where you started by clicking the back arrow at the top-left of the editor `r knitr::include_graphics("images/arrows.png", dpi = 220)` or by pressing Ctrl + F9 (Windows & Linux) or Cmd + F9 (macOS).
:::
 
## Fast feedback via `load_all()` {#code-load-all}

As you add or modify functions defined in files below `R/`, you will naturally want to try them out.
We want to reiterate our strong recommendation to use `devtools::load_all()` to make them available for interactive exploration instead of, for example, `source()`ing files below `R/`.
The main coverage of `load_all()` is in the [workflows chapter](load-all) and `load_all()` also shows up as one of the natural development tasks in [the whole game](whole-game-load-all).
Compared to the alternatives, `load_all()` helps you to iterate more quickly and provides an excellent approximation to the namespace regime of an installed package.

## Code style

We recommend following the tidyverse style guide (<https://style.tidyverse.org>), which goes into much more detail than we can here.
Its format also allows it to be a more dynamic document than this book.

Although the style guide explains the "what" and the "why", another important decision is *how* to enforce a specific code style.
For this we recommend the styler package (<https://styler.r-lib.org>); its default behaviour enforces the tidyverse style guide.
There are many ways to apply styler to your code, depending on the context:

* `styler::style_pkg()` restyles an entire R package.
* `styler::style_dir()` restyles all files in a directory.
* `usethis::use_tidy_style()` is wrapper that applies one of the above functions
  depending on whether the current project is an R package or not.
* `styler::style_file()` restyles a single file.
* `styler::style_text()` restyles a character vector.

:::rstudio-tip
When styler is installed, the RStudio Addins menu will offer several additional ways to style code:

* the active selection
* the active file
* the active package
:::

:::tip
The use of Git or another version control system is optional, but a recommended practice in the long-term.
We explain its importance in \@ref(git).
For example, it's nerve-wracking and somewhat dangerous to apply a function like `styler::style_pkg()` without some way to see exactly what changed and to accept/reject such changes in a granular way.
:::

The styler package can also be integrated with various platforms for hosting source code and doing continuous integration.
For example, the tidyverse packages use a GitHub Action that restyles a package when triggered by a special comment (`/style`) on a pull request.
This allows maintainers to focus on reviewing the substance of the pull request, without having to nitpick small issues of whitespace or indentation[^gha-style][^robot-pedantry].

[^gha-style]: See the [Commands workflow](https://github.com/r-lib/actions/tree/master/examples#commands-workflow) in the [GitHub Actions for the R language](https://github.com/r-lib/actions) repository.

[^robot-pedantry]: The [Robot Pedantry, Human Empathy](https://mikemcquaid.com/2018/06/05/robot-pedantry-human-empathy/) blog post by Mike McQuaid does an excellent job summarizing the benefit of automating tasks like code re-styling.

## Understand when code is executed

Up until now, you've probably been writing __scripts__, R code saved in a file that you execute interactively, perhaps using an IDE and/or `source()`, or noninteractively via `Rscript`.
There are two main differences between code in scripts and packages:

* In a script, code is run ... when you run it! The awkwardness of this
  statement reflects that it's hard to even think about this issue with a
  script. However, we must, in order to appreciate that the code in a package is
  run **when the package is built**. This has big implications for how you write
  the code below `R/`: package code should only create objects, the vast majority
  of which will be functions.
  
* Functions in your package will be used in situations that you didn't imagine.
  This means your functions need to be thoughtful in the way that they interact
  with the outside world.

We expand on the first point here and the second in the next section.

When you `source()` a script, every line of code is executed and the results are immediately made available.
Things are different with package code, because it is loaded in two steps.
When the binary package is built (often, by CRAN) all the code in `R/` is executed and the results are saved.
When you attach a package with `library()`, these cached results are re-loaded and certain objects (mostly functions) are made available for your use.
The full details on what it means for a package to be in binary form are given in \@ref(structure-binary).
We refer to the creation of the binary package as (binary) "build time" and, specifically, we mean when `R CMD INSTALL --build` is run.
(You might think that this is what `R CMD build` does, but that actually makes a bundled package, a.k.a. a "source tarball".)
For macOS and Windows users of CRAN packages, build time is whenever CRAN built the binary package for their OS.
For those who install packages from source, build time is essentially when they (built and) installed the package.

Consider the assignment `x <- Sys.time()`.
If you put this in a script, `x` tells you when the script was `source()`d.
But if you put that same code in a package, `x` tells you when the package binary was _built_.
In section \@ref(package-within-build-time-run-time), we show a complete example of this in the context of forming timestamps inside a package.

The main takeaway is this:

> Any R code outside of a function is suspicious and should be carefully reviewed.

We explore a few real-world examples below that show how easy it is to get burned by this "build time vs. load time" issue.
Luckily, once you diagnose this problem, it is generally not difficult to fix.

### A path returned by `system.file()`

The shinybootstrap2 package once had this code below `R/`:

```{r eval = FALSE}
dataTableDependency <- list(
  htmlDependency(
    "datatables", "1.10.2",
    c(file = system.file("www/datatables", package = "shinybootstrap2")),
    script = "js/jquery.dataTables.min.js"
  ),
  htmlDependency(
    "datatables-bootstrap", "1.10.2",
    c(file = system.file("www/datatables", package = "shinybootstrap2")),
    stylesheet = c("css/dataTables.bootstrap.css", "css/dataTables.extra.css"),
    script = "js/dataTables.bootstrap.js"
  )
)
```

So `dataTableDependency` was an object defined in top-level package code and it depends on some paths obtained via `system.file()`.
As described in [a GitHub issue](https://github.com/rstudio/htmltools/issues/22),

> This works fine when the package is built and tested on the same machine.
> However, if the package is built on one machine and then used on another (as is the case with CRAN binary packages), then this will fail -- the dependency will point to the wrong directory on the host.

The heart of the solution is to make sure that `system.file()` is called from a function, at run time.
Indeed, this fix was made here (in commit [138db47](https://github.com/rstudio/shinybootstrap2/commit/138db47e6bef195f14f6a14f4289ca445e9b2efa#diff-fedcc5cc99f3d44a4caf06f8e6e0ae08)) and in a few other packages that had similar code and a related check was added in `htmlDependency()` itself.
This particular problem would now be caught by `R CMD check`, due to changes that came with [staged installation](https://developer.r-project.org/Blog/public/2019/02/14/staged-install/index.html) as of R 3.6.0.

### Available colours

The crayon package has a function, `crayon::show_ansi_colors()`, that displays an ANSI colour table on your screen, basically to show what sort of styling is possible.
In an early version, the function looked something like this:

```{r eval = FALSE}
show_ansi_colors <- function(colors = num_colors()) {
  if (colors < 8) {
    cat("Colors are not supported")
  } else if (colors < 256) {
    cat(ansi_colors_8, sep = "")
    invisible(ansi_colors_8)
  } else {
    cat(ansi_colors_256, sep = "")
    invisible(ansi_colors_256)
  }
}

ansi_colors_8 <- # code to generate a vector covering basic terminal colors
  
ansi_colors_256 <- # code to generate a vector covering 256 colors
```

where `ansi_colors_8` and `ansi_colors_256` were character vectors exploring a certain set of colours, presumably styled via ANSI escapes.

The problem was those objects were formed and cached when the binary package was built.
Since that often happens on a headless server, this likely happens under conditions where terminal colours might not be enabled or even available.
Users of the installed package could still call `show_ansi_colors()` and `num_colors()` would detect the number of colours supported by their system (256 on most modern computers).
But then an un-coloured object would print to screen (the original GitHub issue is [r-lib/crayon#37](https://github.com/r-lib/crayon/issues/37)).

The solution was to compute the display objects with a function at run time (in commit [e2b368a](https://github.com/r-lib/crayon/commit/e2b368ac27331d82154f85299f18efbc36227caa):

```{r}
show_ansi_colors <- function(colors = num_colors()) {
  if (colors < 8) {
    cat("Colors are not supported")
  } else if (colors < 256) {
    cat(ansi_colors_8(), sep = "")
    invisible(ansi_colors_8())
  } else {
    cat(ansi_colors_256(), sep = "")
    invisible(ansi_colors_256())
  }
}

ansi_colors_8 <- function() {
  # code to generate a vector covering basic terminal colors
}
  
ansi_colors_256 <- function() {
  # code to generate a vector covering 256 colors
}
```

Literally, the same code is used, it is simply pushed down into the body of a function taking no arguments (similar to the shinybootstrap2 example).
Each reference to, e.g., the `ansi_colors_8` object is replaced by a call to the `ansi_colors_8()` function.

The main takeaway is that functions that assess or expose the capabilities of your package on a user's system must fully execute on your user's system.
It's fairly easy to accidentally rely on results that were cached at build time, quite possibly on a different machine.

### Aliasing a function

One last example shows that, even if you are careful to only define functions below `R/`, there are still some subtleties to consider.
Imagine that you want the function `foo()` in your package to basically be an alias for the function `blah()` from some other package, e.g. pkgB.
You might be tempted to do this:

```{r eval = FALSE}
foo <- pkgB::blah
```

However, this will cause `foo()` in your package to reflect the definition of `pkgB::blah()` at the version present on the machine where the binary package is built (often CRAN), at that moment in time.
If a bug is discovered in `pkgB::blah()` and subsequently fixed, your package will still use the older, buggy version, until your package is rebuilt (often by CRAN) and your users upgrade, which is completely out of your control.
This alternative approach protects you from this:

```{r}
foo <- function(...) pkgB::blah(...)
```

Now, when your user calls `foo()`, they are effectively calling `pkgB::blah()`, at the version installed on *their* machine at that very moment.

A real example of this affected an older version of knitr, related to how the default "evaluate" hook was being set to `evaluate::evaluate()` (original issue is [yihui/knitr#1441](https://github.com/yihui/knitr/issues/1441), resolved in commit [d6b53e0](https://github.com/yihui/knitr/commit/d6b53e0f15a8afd1de4987a86931ba54f886278d)).

## Respect the R landscape {#code-r-landscape}

Another big difference between a script and a package is that other people are going to use your package, and they're going to use it in situations that you never imagined.
This means you need to pay attention to the R landscape, which includes not just the available functions and objects, but all the global settings.

You have changed the R landscape if you've loaded a package with `library()`, or changed a global option with `options()`, or modified the working directory with `setwd()`.
If the behaviour of _other_ functions differs before and after running your function, you've modified the landscape.
The [side effects section of the "package within" chapter](#package-within-side-effects) has a concrete example of this involving time zones and the locale-specific printing of datetimes.
Changing the landscape is bad because it makes code much harder to understand.

There are some functions that modify global settings that you should never use because there are better alternatives:

* __Don't use `library()` or `require()`__. These modify the search path, 
  affecting what functions are available from the global environment. 
  Intead, you should use the `DESCRIPTION` to specify your package's
  requirements, as described in chapter \@ref(description). This also makes sure
  those packages are installed when your package is installed.
  
* __Never use `source()`__ to load code from a file. `source()` modifies the
  current environment, inserting the results of executing the code. There is no
  reason to use `source()` inside your package, i.e. in a file below `R/`.
  Sometimes people `source()` files below `R/` during package development, but
  as we've explained in \@ref(load-all) and \@ref(code-load-all), `load_all()`
  is a much better way to load your current code for exploration. If you're
  using `source()` to create a dataset, it is better to use the methods in
  \@ref(data) for including data in a package.

Here is a non-exhaustive list of other functions that should be used with caution:

* `options()`
* `par()`
* `setwd()`
* `Sys.setenv()`
* `Sys.setlocale()`
* `set.seed()` (or anything that changes the state of the random number
  generator) *TODO: maybe tell one or more of the scary stories in
  <https://github.com/hadley/r-pkgs/issues/447>*

If you must use them, make sure to clean up after yourself.
Below we show how to do this using functions from the withr package and in base R.

The flip side of this coin is that you should avoid relying on the user's landscape, which might be different to yours.
For example, functions like `read.csv()` are dangerous because the value of `stringsAsFactors` argument comes from the global option `stringsAsFactors`.
If you expect it to be `TRUE` (the default), and the user has set it to be `FALSE`, your code might fail.

*TODO: update or replace this example in light of `stringsAsFactors` changes.*

### Manage state with withr

The withr package is inspired by `base::on.exit()` and provides a flexible `on.exit()`-like toolkit (`on.exit()` itself is covered in the next section).
`withr::defer()` can be used as a drop-in replacement for `on.exit()`, but the real reason to use it is to get its default "stack-like" behaviour and to use its `envir` argument (in more advanced usage).

The general pattern is to capture the original state, schedule its eventual restoration "on exit", then make the state change.
Some setters, such as `options()` or `par()`, return the old value when you provide a new value, leading to usage that looks like this:

```{r, eval = FALSE}
f <- function(x, y, z) {
  ...
  old <- options(mfrow = c(2, 2), pty = "s")
  defer(options(old))
  ...
}
```

Certain state changes, such as modifying session options, come up so often that withr offers pre-made helpers.
Here a few of the state change helpers in withr that you are most likely to find useful:

| Do / undo this              | withr functions                     |
|-----------------------------|-------------------------------------|
| Set an R option             | `with_options()`, `local_options()` |
| Set an environment variable | `with_envvar()`, `local_envvar()`   |
| Change working directory    | `with_dir()`, `local_dir()`         |
| Set a graphics parameter    | `with_par()`, `local_par()`         |

You'll notice each helper comes in two forms that are useful in different situations:

* `with_*()` functions are best for executing small snippets of code with a
  temporarily modified state. (These functions are inspired by how
  `base::with()` works.)
    ```{r eval = FALSE}
    f <- function(x, sig_digits) {
      # imagine lots of code here
      withr::with_options(
        list(digits = sig_digits),
        print(x)
      )
      # ... and a lot more code here
    }
    ```
* `local_*()` functions are best for modifying state "from now until the
  function exits".
    ```{r eval = FALSE}
    g <- function(x, sig_digits) {
      withr::local_options(list(digits = sig_digits))
      print(x)
      # imagine lots of code here
    }
    ```

Developing code interactively with withr is pleasant, because deferred actions can be scheduled even on the global environment.
Those cleanup actions can then be executed with `withr::deferred_run()` or cleared without exeuction with `withr::deferred_clear()`.
Without this feature, it can be tricky to experiment with code that needs cleanup "on exit", because it behaves so differently when executed in the console versus at arm's length inside a function.

More in-depth coverage is given in the withr vignette [Changing and restoring state](https://withr.r-lib.org/articles/changing-and-restoring-state.html) and withr will also prove useful when we talk about testing in chapter \@ref(tests).

### Restore state with `base::on.exit()`

Here is how the general "save, schedule restoration, change" pattern looks when using `base::on.exit()`.
  
```{r, eval = FALSE}
f <- function(x, y, z) {
  ...
  old <- options(mfrow = c(2, 2), pty = "s")
  on.exit(options(old), add = TRUE)
  ...
}
```

Other state changes aren't available with that sort of setter and you must implement it yourself.

```{r, eval = FALSE}
g <- function(a, b, c) {
  ...
  scratch_file <- tempfile()
  on.exit(unlink(scratch_file), add = TRUE)
  file.create(scratch_file)
  ...
}
```

Note that we specify `on.exit(..., add = TRUE)`, because you almost always want this behaviour, i.e. to *add* to the list of deferred cleanup tasks rather than to *replace* them entirely.
This (and the default value of `after`) are related to our preference for `withr::defer()`, when we're willing to take a dependency on withr.
These issues are explored in a [withr vignette](https://withr.r-lib.org/articles/changing-and-restoring-state.html).

### Isolate side effects

Creating plots and printing output to the console are two other ways of affecting the global R environment.
Often you can't avoid these (because they're important!) but it's good practice to isolate them in functions that __only__ produce output.
This also makes it easier for other people to repurpose your work for new uses.
For example, if you separate data preparation and plotting into two functions, others can use your data prep work (which is often the hardest part!) to create new visualisations.

### When you __do__ need side-effects

Occasionally, packages do need side-effects.
This is most common if your package talks to an external system --- you might need to do some initial setup when the package loads.
To do that, you can use two special functions: `.onLoad()` and `.onAttach()`.
These are called when the package is loaded and attached.
You'll learn about the distinction between the two in [Namespaces](#namespace).
For now, you should always use `.onLoad()` unless explicitly directed otherwise.

Some common uses of `.onLoad()` and `.onAttach()` are:

*   To display an informative message when the package loads. This might make 
    usage conditions clear or display package capabilities based on current
    system conditions. Startup messages are one place where you should use
    `.onAttach()` instead of `.onLoad()`. To display startup messages, always
    use `packageStartupMessage()`, and not `message()`. (This allows
    `suppressPackageStartupMessages()` to selectively suppress package startup
    messages).

    ```{r, eval = FALSE}
    .onAttach <- function(libname, pkgname) {
      packageStartupMessage("Welcome to my package")
    }
    ```
    
*   To set custom options for your package with `options()`. To avoid conflicts
    with other packages, ensure that you prefix option names with the name
    of your package. Also be careful not to override options that the user
    has already set.
    
    *TODO: update this to reflect current usethis options.*
    I use the following code in devtools to set up useful options:
    
    ```{r, eval = FALSE}
    .onLoad <- function(libname, pkgname) {
      op <- options()
      op.devtools <- list(
        devtools.path = "~/R-dev",
        devtools.install.args = "",
        devtools.name = "Your name goes here",
        devtools.desc.author = "First Last <first.last@example.com> [aut, cre]",
        devtools.desc.license = "What license is it under?",
        devtools.desc.suggests = NULL,
        devtools.desc = list()
      )
      toset <- !(names(op.devtools) %in% names(op))
      if(any(toset)) options(op.devtools[toset])
    
      invisible()
    }
    ```
    
    Then devtools functions can use e.g. `getOption("devtools.name")` to 
    get the name of the package author, and know that a sensible default value
    has already been set.
    
*   To connect R to another programming language. For example, if you use rJava
    to talk to a `.jar` file, you need to call `rJava::.jpackage()`. To
    make C++ classes available as reference classes in R with Rcpp modules,
    you call `Rcpp::loadRcppModules()`. *TODO: update / remove this?*

*   To register vignette engines with `tools::vignetteEngine()`.
     *TODO: update / remove this?*

As you can see in the examples, `.onLoad()` and `.onAttach()` are called with two arguments: `libname` and `pkgname`.
They're rarely used (they're a holdover from the days when you needed to use `library.dynam()` to load compiled code).
They give the path where the package is installed (the "library"), and the name of the package.

If you use `.onLoad()`, consider using `.onUnload()` to clean up any side effects.
By convention, `.onLoad()` and friends are usually saved in a file called `R/zzz.R`.
(Note that `.First.lib()` and `.Last.lib()` are old versions of `.onLoad()` and `.onUnload()` and should no longer be used.)

## Constant health checks

Here is a typical sequence of calls when using devtools for package development:

1. Edit one or more files below `R/`.
1. `document()` (if you've made any changes that impact help files or NAMESPACE)
1. `load_all()`
1. Run some examples interactively.
1. `test()` (or `test_file()`)
1. `check()`

An interesting question is how frequently and rapidly you move through this development cycle.
We often find ourselves running through the above sequence several times in an hour or in a day while adding or modifying a single function.

Those newer to package development might be most comfortable slinging R code and much less comfortable writing and compiling documentation, simulating package build & installation, testing, and running `R CMD check`.
And it is human nature to embrace the familiar and postpone the unfamiliar.
This often leads to a dysfunctional workflow where the full sequence above unfolds infrequently, maybe once per month or every couple of months, very slowly and often with great pain:

1. Edit one or more files below `R/`.
1. Build, install, and use the package. Iterate occasionally with previous step.
1. Write documentation (once the code is "done").
1. Write tests (once the code is "done").
1. Run `R CMD check` right before submitting to CRAN or releasing in some other
   way.
   
We've already talked about the value of fast feedback, in the context of `load_all()`.
But this also applies to running `document()`, `test()`, and `check()`.
There are defects you just can't detect from using `load_all()` and running a few interactive examples that are immediately revealed by more formal checks.
Finding and fixing 5 bugs, one at a time, right after you created each one is much easier than troubleshooting all 5 at once (possibly interacting with each other), weeks or months after you last touched the code.

## CRAN notes {#code-cran}

(Each chapter will finish with some hints for submitting your package to CRAN.
If you don't plan on submitting your package to CRAN, feel free to ignore them!)

If you're planning on submitting your package to CRAN, you must use only ASCII characters in your `.R` files.
In practice, this means you are limited to the digits 0 to 9, lowercase letters 'a' to 'z', uppercase letters 'A' to 'Z', and common punctuation.

But sometimes you need to inline a small bit of character data that includes, e.g., a Greek letter (µ), an accented character (ü), or a symbol (30°).
You can use any Unicode character as long as you specify it in the special Unicode escape `"\u1234"` format.
The easiest way to find the correct code point is to use `stringi::stri_escape_unicode()`:

```{r}
x <- "This is a bullet •"
y <- "This is a bullet \u2022"
identical(x, y)
cat(stringi::stri_escape_unicode(x))
```

Sometimes you have the opposite problem.
You don't *intentionally* have any non-ASCII characters in your R code, but automated checks reveal that you do.

```
W  checking R files for non-ASCII characters ...
   Found the following file with non-ASCII characters:
     foo.R
   Portable packages must use only ASCII characters in their R code,
   except perhaps in comments.
   Use \uxxxx escapes for other characters.
```

The most common offenders are "curly" or "smart" single and double quotes that sneak in through copy/paste.
The functions `tools::showNonASCII()` and `tools::showNonASCIIfile(file)` help you find the offending file(s) and line(s).

```{r eval = FALSE}
tools::showNonASCIIfile("R/foo.R")
#> 666: #' If you<e2><80><99>ve copy/pasted quotes, watch out!
```
